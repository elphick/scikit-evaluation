{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Partition Estimator\n\nThere are times when the modeller or subject-matter expert feels the need to test estimation domains (data partitions).\nThe partitions are defined by setting a criteria string per estimation domain.  The criteria string is used to\nfilter the incoming feature dataframe before fitting the model for that partition.\n\nThe idea supporting partitioning is that each partition, having a specific structure can be fitted better.\nThe trade-off of course is that when partitioned, less data is available for fitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport plotly\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.utils.validation import check_is_fitted\n\nfrom elphick.sklearn_viz.components.estimators import PartitionRegressor\nfrom elphick.sklearn_viz.features import plot_feature_importance, OutlierDetection\nfrom elphick.sklearn_viz.model_selection import ModelSelection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Regression Data\n\nThe California housing dataset will be loaded to demonstrate the regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y = fetch_california_housing(return_X_y=True, as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove Outliers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We will remove the outliers from the dataset.  This is not a necessary step, but it will help to\n# demonstrate the partitioning.\n\nod: OutlierDetection = OutlierDetection(x=x, pca_spec=2)\ndetected_outliers: pd.Series = od.data['outlier']\n\nx = x.query('@detected_outliers == False')\ny = y.loc[x.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nxy_train: pd.DataFrame = pd.concat([x_train, y_train], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numerical_cols = x.select_dtypes(include=[float]).columns.to_list()\ncategorical_cols = x.select_dtypes(include=[object, 'category']).columns.to_list()\n\ncategorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\nnumerical_preprocessor = StandardScaler()\npreprocessor = ColumnTransformer(\n    [\n        (\"one-hot-encoder\", categorical_preprocessor, categorical_cols),\n        (\"standard_scaler\", numerical_preprocessor, numerical_cols),\n    ], verbose_feature_names_out=False\n)\n\npp: Pipeline = make_pipeline(preprocessor).set_output(transform='pandas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Estimators\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The baseline model will simply be fitted as normal - no partitions will be applied.\n\nbase_mdl: Pipeline = make_pipeline(pp, LinearRegression())\nbase_mdl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Partitioned Model\n\nWe will create the criteria for 3 arbitrary partitions of room size at the lower and upper quartile.\nWe'd like to work in the incoming feature space, but the PartitionRegressor will need the criteria in the\npost-processed space, since that is the only data it sees.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_train['AveRooms'].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "partition_criteria: dict = {'small': 'AveRooms < 4.4',\n                            'medium': '(AveRooms >= 4.4) and (AveRooms < 6.0)',\n                            'large': 'AveRooms >= 6.0'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For now this is conversion must be done by the user, manually\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pp.fit_transform(x_train)['AveRooms'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "partition_criteria: dict = {'small': 'AveRooms < -0.43',\n                            'medium': '(AveRooms >= -0.43) and (AveRooms < 0.24)',\n                            'large': 'AveRooms >= 0.24'}\n\npartition_mdl: Pipeline = make_pipeline(pp, PartitionRegressor(LinearRegression(),\n                                                               partition_defs=partition_criteria))\npartition_mdl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the model visualisation above, expand the arrow next to the partition names (small, medium, large) to\nsee the criteria.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip::\n\n   A trick to avoid transforming the partition criteria values is to embed the preprocessor into every model,\n   rather than having a common preprocessor.  This will create additional computational overhead but is\n   perhaps a nice way of simplifying the workflow.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo Fit and Predict\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_mdl.fit(X=x_train, y=y_train)\ncheck_is_fitted(base_mdl)\nest_base = pd.Series(base_mdl.predict(X=x_test), index=x_test.index, name='base_est')\n\npartition_mdl.fit(X=x_train, y=y_train)\ncheck_is_fitted(partition_mdl)\nest_partition = partition_mdl.predict(X=x_test)\n\nest: pd.DataFrame = pd.concat([est_base, est_partition], axis=1)\nest.columns = ['base_est', 'partition_est']\nest.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ms: ModelSelection = ModelSelection(estimators={'base-model': base_mdl,\n                                                'partition-model': partition_mdl},\n                                    datasets=xy_train,\n                                    target='MedHouseVal',\n                                    group=partition_mdl[-1].domains_, random_state=123)\nfig = ms.plot(show_group=True, metrics=['r2_score'])\nfig.update_layout(height=600)\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To some extent the error margin (notch width) will be driven by the number of samples.\nLet's check the sample counts.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "partition_mdl[-1].domains_.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>1. In this case the partitioning did not deliver any statistically significant improvement, but a directional improvement.\n   2. It appears that (for the small class) the error margins are wider for the partitioned model,\n      caused by lower sample count for that class in the fitted model.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importance\n\nWe can check that the feature imports works as expected on our new Estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plot_feature_importance(partition_mdl, permute=True, x_test=x_train, y_test=y_train)\nfig"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
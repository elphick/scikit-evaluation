{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Model Selection\n\nThis example demonstrates a model selection plot using cross validation.\n\nCode has been adapted from the\n[machinelearningmastery example](https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nfrom typing import Dict\n\nimport numpy as np\nimport pandas\nimport pandas as pd\nimport plotly\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom elphick.sklearn_viz.model_selection import ModelSelection, plot_model_selection, metrics\nfrom elphick.sklearn_viz.model_selection.models import Models\n\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s %(levelname)s %(module)s - %(funcName)s: %(message)s',\n                    datefmt='%Y-%m-%dT%H:%M:%S%z')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n\nOnce loaded we'll create the train-test split for a classification problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\nx = pd.DataFrame(array[:, 0:8], columns=names[0:8])\ny = pd.Series(array[:, 8], name=names[8])\nxy: pd.DataFrame = pd.concat([x, y], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiate\n\nCreate an optional pre-processor as a sklearn Pipeline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(1234)\npp: Pipeline = make_pipeline(StandardScaler())\nmodels_to_test: Dict = Models().fast_classifiers()\npp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot using the function\n\nThe box colors are scaled to provide a relative indication of performance based on the score (Kudos to\n[Shah Newaz Khan](https://towardsdatascience.com/applying-a-custom-colormap-with-plotly-boxplots-5d3acf59e193))\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plot_model_selection(estimators=models_to_test, datasets=xy, target='class', pre_processor=pp)\nfig.update_layout(height=600)\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot using the object\n\nThe alternative to using the function is to instantiate a ModelSelection object.  This has the advantage of\npersisting the data, which provides greater flexibility and faster re-plotting.\nIf metrics as provided additional subplots are provided - however since metrics have no concept of \"greater-is-good\"\nlike a scorer, they are not coloured.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ms: ModelSelection = ModelSelection(estimators=models_to_test, datasets=xy, target='class', pre_processor=pp,\n                                    k_folds=30, verbosity=0)\nfig = ms.plot(title='Model Selection', metrics='f1')\nfig.update_layout(height=600)\n# noinspection PyTypeChecker\nplotly.io.show(fig)  # this call to show will set the thumbnail for use in the gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ms.results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regressor Model Selection\n\nOf course we're not limited to classification problems.  We will demonstrate a regression problem, with multiple\nmetrics.  We prepare a `group` variable (a pd.Series) in order to calculate the metrics by group for each fold.\n\nThis cross-validation takes a bit longer, so we set the n_jobs to -2, to fit in parallel, while preserving a core to\nensure the system can respond.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diabetes = load_diabetes(as_frame=True)\nx, y = diabetes.data, diabetes.target\ny.name = \"progression\"\nxy: pd.DataFrame = pd.concat([x, y], axis=1)\ngroup: pd.Series = pd.Series(x['sex'] > 0, name='grp_sex', index=x.index)\n\npp: Pipeline = make_pipeline(StandardScaler())\nmodels_to_test: Dict = Models().fast_regressors()\n\nms: ModelSelection = ModelSelection(estimators=models_to_test, datasets=xy, target='progression', pre_processor=pp,\n                                    k_folds=30, scorer='r2', group=group,\n                                    metrics={'moe': metrics.moe_95, 'me': metrics.mean_error},\n                                    n_jobs=-2, verbosity=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we'll view the plot, but we will not (yet) leverage the group variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ms.plot(metrics=['moe', 'me'])\nfig.update_layout(height=700)\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will re-plot using group.  This is fast, since the fitting metrics were calculated when the first plot was\ncreated, and do not need to be calculated again.\n\nPlotting by group can (hopefully) provide evidence that metrics are consistent across groups.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ms.plot(metrics=['moe', 'me'], show_group=True, col_wrap=2)\nfig.update_layout(height=700)\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clearly, plot real estate will become a problem for more than 2 or 3 classes - here we used col_wrap mitigate that.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Datasets\n\nNext we will demonstrate a single Algorithm with multiple datasets.  This is useful when exploring features that\nimprove model performance.  We modify DS2 by removing a feature and sampling 40% of the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets: Dict = {'DS1': xy, 'DS2': xy.drop(columns=['age']).sample(frac=0.4)}\n\nfig = plot_model_selection(estimators=LinearRegression(), datasets=datasets, target='progression', pre_processor=pp,\n                           k_folds=30)\nfig.update_layout(height=600)\nfig"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}